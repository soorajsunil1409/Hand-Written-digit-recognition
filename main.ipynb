{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'test': DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1)\n",
    "        self.conv2_dropout = nn.Dropout2d()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=20*4*4, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = F.relu(self.conv2_dropout(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = x.view(-1, 20*4*4)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x160e3e5e0>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = CNN()\n",
    "model1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "def train(epoch):\n",
    "    model1.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model1(data)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Epoch: {epoch} | [{batch_idx * len(data)} / {len(loaders['train'].dataset)}] | Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model1.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            output = model1(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"Average Loss: {test_loss} | Correct: {correct} / 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/g1zfkg_x123fctpz09drl4h00000gn/T/ipykernel_3189/2886317348.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | [0 / 60000] | Loss: 2.304447889328003\n",
      "Epoch: 1 | [2000 / 60000] | Loss: 2.291552782058716\n",
      "Epoch: 1 | [4000 / 60000] | Loss: 2.1775052547454834\n",
      "Epoch: 1 | [6000 / 60000] | Loss: 2.0189530849456787\n",
      "Epoch: 1 | [8000 / 60000] | Loss: 1.9247615337371826\n",
      "Epoch: 1 | [10000 / 60000] | Loss: 1.8670361042022705\n",
      "Epoch: 1 | [12000 / 60000] | Loss: 1.872247576713562\n",
      "Epoch: 1 | [14000 / 60000] | Loss: 1.7582632303237915\n",
      "Epoch: 1 | [16000 / 60000] | Loss: 1.748719334602356\n",
      "Epoch: 1 | [18000 / 60000] | Loss: 1.6514629125595093\n",
      "Epoch: 1 | [20000 / 60000] | Loss: 1.6942447423934937\n",
      "Epoch: 1 | [22000 / 60000] | Loss: 1.7052814960479736\n",
      "Epoch: 1 | [24000 / 60000] | Loss: 1.6725753545761108\n",
      "Epoch: 1 | [26000 / 60000] | Loss: 1.6708776950836182\n",
      "Epoch: 1 | [28000 / 60000] | Loss: 1.618985652923584\n",
      "Epoch: 1 | [30000 / 60000] | Loss: 1.714369773864746\n",
      "Epoch: 1 | [32000 / 60000] | Loss: 1.6654967069625854\n",
      "Epoch: 1 | [34000 / 60000] | Loss: 1.6816015243530273\n",
      "Epoch: 1 | [36000 / 60000] | Loss: 1.626257300376892\n",
      "Epoch: 1 | [38000 / 60000] | Loss: 1.6598941087722778\n",
      "Epoch: 1 | [40000 / 60000] | Loss: 1.647937297821045\n",
      "Epoch: 1 | [42000 / 60000] | Loss: 1.656510829925537\n",
      "Epoch: 1 | [44000 / 60000] | Loss: 1.629116177558899\n",
      "Epoch: 1 | [46000 / 60000] | Loss: 1.6537164449691772\n",
      "Epoch: 1 | [48000 / 60000] | Loss: 1.576608419418335\n",
      "Epoch: 1 | [50000 / 60000] | Loss: 1.5633152723312378\n",
      "Epoch: 1 | [52000 / 60000] | Loss: 1.58388090133667\n",
      "Epoch: 1 | [54000 / 60000] | Loss: 1.678420066833496\n",
      "Epoch: 1 | [56000 / 60000] | Loss: 1.5975086688995361\n",
      "Epoch: 1 | [58000 / 60000] | Loss: 1.583831787109375\n",
      "Average Loss: 0.01525765633583069 | Correct: 9375 / 10000\n",
      "Epoch: 2 | [0 / 60000] | Loss: 1.574031949043274\n",
      "Epoch: 2 | [2000 / 60000] | Loss: 1.654970407485962\n",
      "Epoch: 2 | [4000 / 60000] | Loss: 1.589811086654663\n",
      "Epoch: 2 | [6000 / 60000] | Loss: 1.551527976989746\n",
      "Epoch: 2 | [8000 / 60000] | Loss: 1.5719267129898071\n",
      "Epoch: 2 | [10000 / 60000] | Loss: 1.595245361328125\n",
      "Epoch: 2 | [12000 / 60000] | Loss: 1.593511939048767\n",
      "Epoch: 2 | [14000 / 60000] | Loss: 1.5429764986038208\n",
      "Epoch: 2 | [16000 / 60000] | Loss: 1.5932997465133667\n",
      "Epoch: 2 | [18000 / 60000] | Loss: 1.5662868022918701\n",
      "Epoch: 2 | [20000 / 60000] | Loss: 1.6027708053588867\n",
      "Epoch: 2 | [22000 / 60000] | Loss: 1.5964841842651367\n",
      "Epoch: 2 | [24000 / 60000] | Loss: 1.6064492464065552\n",
      "Epoch: 2 | [26000 / 60000] | Loss: 1.587907314300537\n",
      "Epoch: 2 | [28000 / 60000] | Loss: 1.5760971307754517\n",
      "Epoch: 2 | [30000 / 60000] | Loss: 1.5511893033981323\n",
      "Epoch: 2 | [32000 / 60000] | Loss: 1.5788943767547607\n",
      "Epoch: 2 | [34000 / 60000] | Loss: 1.5605281591415405\n",
      "Epoch: 2 | [36000 / 60000] | Loss: 1.584786057472229\n",
      "Epoch: 2 | [38000 / 60000] | Loss: 1.5452841520309448\n",
      "Epoch: 2 | [40000 / 60000] | Loss: 1.580378770828247\n",
      "Epoch: 2 | [42000 / 60000] | Loss: 1.5553288459777832\n",
      "Epoch: 2 | [44000 / 60000] | Loss: 1.5941740274429321\n",
      "Epoch: 2 | [46000 / 60000] | Loss: 1.555722951889038\n",
      "Epoch: 2 | [48000 / 60000] | Loss: 1.5696088075637817\n",
      "Epoch: 2 | [50000 / 60000] | Loss: 1.518896460533142\n",
      "Epoch: 2 | [52000 / 60000] | Loss: 1.544386863708496\n",
      "Epoch: 2 | [54000 / 60000] | Loss: 1.5264158248901367\n",
      "Epoch: 2 | [56000 / 60000] | Loss: 1.5824072360992432\n",
      "Epoch: 2 | [58000 / 60000] | Loss: 1.578283667564392\n",
      "Average Loss: 0.015074950051307679 | Correct: 9537 / 10000\n",
      "Epoch: 3 | [0 / 60000] | Loss: 1.5341415405273438\n",
      "Epoch: 3 | [2000 / 60000] | Loss: 1.5445425510406494\n",
      "Epoch: 3 | [4000 / 60000] | Loss: 1.5386120080947876\n",
      "Epoch: 3 | [6000 / 60000] | Loss: 1.5895904302597046\n",
      "Epoch: 3 | [8000 / 60000] | Loss: 1.5410139560699463\n",
      "Epoch: 3 | [10000 / 60000] | Loss: 1.5667856931686401\n",
      "Epoch: 3 | [12000 / 60000] | Loss: 1.6116567850112915\n",
      "Epoch: 3 | [14000 / 60000] | Loss: 1.539903163909912\n",
      "Epoch: 3 | [16000 / 60000] | Loss: 1.5766104459762573\n",
      "Epoch: 3 | [18000 / 60000] | Loss: 1.5890542268753052\n",
      "Epoch: 3 | [20000 / 60000] | Loss: 1.543328046798706\n",
      "Epoch: 3 | [22000 / 60000] | Loss: 1.5220774412155151\n",
      "Epoch: 3 | [24000 / 60000] | Loss: 1.5728371143341064\n",
      "Epoch: 3 | [26000 / 60000] | Loss: 1.5511467456817627\n",
      "Epoch: 3 | [28000 / 60000] | Loss: 1.5676912069320679\n",
      "Epoch: 3 | [30000 / 60000] | Loss: 1.551743984222412\n",
      "Epoch: 3 | [32000 / 60000] | Loss: 1.5745112895965576\n",
      "Epoch: 3 | [34000 / 60000] | Loss: 1.5481817722320557\n",
      "Epoch: 3 | [36000 / 60000] | Loss: 1.531428337097168\n",
      "Epoch: 3 | [38000 / 60000] | Loss: 1.5291558504104614\n",
      "Epoch: 3 | [40000 / 60000] | Loss: 1.5259953737258911\n",
      "Epoch: 3 | [42000 / 60000] | Loss: 1.54840886592865\n",
      "Epoch: 3 | [44000 / 60000] | Loss: 1.5317387580871582\n",
      "Epoch: 3 | [46000 / 60000] | Loss: 1.5203280448913574\n",
      "Epoch: 3 | [48000 / 60000] | Loss: 1.5759867429733276\n",
      "Epoch: 3 | [50000 / 60000] | Loss: 1.5314013957977295\n",
      "Epoch: 3 | [52000 / 60000] | Loss: 1.5463883876800537\n",
      "Epoch: 3 | [54000 / 60000] | Loss: 1.545332670211792\n",
      "Epoch: 3 | [56000 / 60000] | Loss: 1.5761651992797852\n",
      "Epoch: 3 | [58000 / 60000] | Loss: 1.5237860679626465\n",
      "Average Loss: 0.015006833446025849 | Correct: 9609 / 10000\n",
      "Epoch: 4 | [0 / 60000] | Loss: 1.595816969871521\n",
      "Epoch: 4 | [2000 / 60000] | Loss: 1.5479198694229126\n",
      "Epoch: 4 | [4000 / 60000] | Loss: 1.5576950311660767\n",
      "Epoch: 4 | [6000 / 60000] | Loss: 1.5596041679382324\n",
      "Epoch: 4 | [8000 / 60000] | Loss: 1.539840817451477\n",
      "Epoch: 4 | [10000 / 60000] | Loss: 1.5382356643676758\n",
      "Epoch: 4 | [12000 / 60000] | Loss: 1.5365524291992188\n",
      "Epoch: 4 | [14000 / 60000] | Loss: 1.4956107139587402\n",
      "Epoch: 4 | [16000 / 60000] | Loss: 1.5058016777038574\n",
      "Epoch: 4 | [18000 / 60000] | Loss: 1.5493652820587158\n",
      "Epoch: 4 | [20000 / 60000] | Loss: 1.5043487548828125\n",
      "Epoch: 4 | [22000 / 60000] | Loss: 1.5269488096237183\n",
      "Epoch: 4 | [24000 / 60000] | Loss: 1.5222206115722656\n",
      "Epoch: 4 | [26000 / 60000] | Loss: 1.5332034826278687\n",
      "Epoch: 4 | [28000 / 60000] | Loss: 1.5315710306167603\n",
      "Epoch: 4 | [30000 / 60000] | Loss: 1.5165880918502808\n",
      "Epoch: 4 | [32000 / 60000] | Loss: 1.5436347723007202\n",
      "Epoch: 4 | [34000 / 60000] | Loss: 1.5318825244903564\n",
      "Epoch: 4 | [36000 / 60000] | Loss: 1.5451722145080566\n",
      "Epoch: 4 | [38000 / 60000] | Loss: 1.598158836364746\n",
      "Epoch: 4 | [40000 / 60000] | Loss: 1.5151872634887695\n",
      "Epoch: 4 | [42000 / 60000] | Loss: 1.5180610418319702\n",
      "Epoch: 4 | [44000 / 60000] | Loss: 1.4953012466430664\n",
      "Epoch: 4 | [46000 / 60000] | Loss: 1.536807656288147\n",
      "Epoch: 4 | [48000 / 60000] | Loss: 1.568518877029419\n",
      "Epoch: 4 | [50000 / 60000] | Loss: 1.5201133489608765\n",
      "Epoch: 4 | [52000 / 60000] | Loss: 1.496019721031189\n",
      "Epoch: 4 | [54000 / 60000] | Loss: 1.521878719329834\n",
      "Epoch: 4 | [56000 / 60000] | Loss: 1.5073935985565186\n",
      "Epoch: 4 | [58000 / 60000] | Loss: 1.5513769388198853\n",
      "Average Loss: 0.014966703772544861 | Correct: 9640 / 10000\n",
      "Epoch: 5 | [0 / 60000] | Loss: 1.5813817977905273\n",
      "Epoch: 5 | [2000 / 60000] | Loss: 1.534866452217102\n",
      "Epoch: 5 | [4000 / 60000] | Loss: 1.5848076343536377\n",
      "Epoch: 5 | [6000 / 60000] | Loss: 1.5391473770141602\n",
      "Epoch: 5 | [8000 / 60000] | Loss: 1.5881344079971313\n",
      "Epoch: 5 | [10000 / 60000] | Loss: 1.5418411493301392\n",
      "Epoch: 5 | [12000 / 60000] | Loss: 1.5601310729980469\n",
      "Epoch: 5 | [14000 / 60000] | Loss: 1.527843952178955\n",
      "Epoch: 5 | [16000 / 60000] | Loss: 1.5554088354110718\n",
      "Epoch: 5 | [18000 / 60000] | Loss: 1.541419267654419\n",
      "Epoch: 5 | [20000 / 60000] | Loss: 1.550168752670288\n",
      "Epoch: 5 | [22000 / 60000] | Loss: 1.5406718254089355\n",
      "Epoch: 5 | [24000 / 60000] | Loss: 1.5433883666992188\n",
      "Epoch: 5 | [26000 / 60000] | Loss: 1.5523077249526978\n",
      "Epoch: 5 | [28000 / 60000] | Loss: 1.525242567062378\n",
      "Epoch: 5 | [30000 / 60000] | Loss: 1.5208158493041992\n",
      "Epoch: 5 | [32000 / 60000] | Loss: 1.5315756797790527\n",
      "Epoch: 5 | [34000 / 60000] | Loss: 1.5253210067749023\n",
      "Epoch: 5 | [36000 / 60000] | Loss: 1.4973266124725342\n",
      "Epoch: 5 | [38000 / 60000] | Loss: 1.5341477394104004\n",
      "Epoch: 5 | [40000 / 60000] | Loss: 1.583682656288147\n",
      "Epoch: 5 | [42000 / 60000] | Loss: 1.5406280755996704\n",
      "Epoch: 5 | [44000 / 60000] | Loss: 1.5520018339157104\n",
      "Epoch: 5 | [46000 / 60000] | Loss: 1.538771629333496\n",
      "Epoch: 5 | [48000 / 60000] | Loss: 1.5162930488586426\n",
      "Epoch: 5 | [50000 / 60000] | Loss: 1.5460134744644165\n",
      "Epoch: 5 | [52000 / 60000] | Loss: 1.5452228784561157\n",
      "Epoch: 5 | [54000 / 60000] | Loss: 1.5504287481307983\n",
      "Epoch: 5 | [56000 / 60000] | Loss: 1.512837529182434\n",
      "Epoch: 5 | [58000 / 60000] | Loss: 1.5577337741851807\n",
      "Average Loss: 0.014933114743232728 | Correct: 9678 / 10000\n",
      "Epoch: 6 | [0 / 60000] | Loss: 1.557560920715332\n",
      "Epoch: 6 | [2000 / 60000] | Loss: 1.549989938735962\n",
      "Epoch: 6 | [4000 / 60000] | Loss: 1.5080260038375854\n",
      "Epoch: 6 | [6000 / 60000] | Loss: 1.4891263246536255\n",
      "Epoch: 6 | [8000 / 60000] | Loss: 1.5861806869506836\n",
      "Epoch: 6 | [10000 / 60000] | Loss: 1.5637015104293823\n",
      "Epoch: 6 | [12000 / 60000] | Loss: 1.518631935119629\n",
      "Epoch: 6 | [14000 / 60000] | Loss: 1.5459767580032349\n",
      "Epoch: 6 | [16000 / 60000] | Loss: 1.5513056516647339\n",
      "Epoch: 6 | [18000 / 60000] | Loss: 1.5291591882705688\n",
      "Epoch: 6 | [20000 / 60000] | Loss: 1.5570764541625977\n",
      "Epoch: 6 | [22000 / 60000] | Loss: 1.5131055116653442\n",
      "Epoch: 6 | [24000 / 60000] | Loss: 1.558205008506775\n",
      "Epoch: 6 | [26000 / 60000] | Loss: 1.5412880182266235\n",
      "Epoch: 6 | [28000 / 60000] | Loss: 1.5789897441864014\n",
      "Epoch: 6 | [30000 / 60000] | Loss: 1.5227841138839722\n",
      "Epoch: 6 | [32000 / 60000] | Loss: 1.542467474937439\n",
      "Epoch: 6 | [34000 / 60000] | Loss: 1.5323843955993652\n",
      "Epoch: 6 | [36000 / 60000] | Loss: 1.5141788721084595\n",
      "Epoch: 6 | [38000 / 60000] | Loss: 1.520412564277649\n",
      "Epoch: 6 | [40000 / 60000] | Loss: 1.5298019647598267\n",
      "Epoch: 6 | [42000 / 60000] | Loss: 1.5365588665008545\n",
      "Epoch: 6 | [44000 / 60000] | Loss: 1.5315383672714233\n",
      "Epoch: 6 | [46000 / 60000] | Loss: 1.528135061264038\n",
      "Epoch: 6 | [48000 / 60000] | Loss: 1.5258684158325195\n",
      "Epoch: 6 | [50000 / 60000] | Loss: 1.566693902015686\n",
      "Epoch: 6 | [52000 / 60000] | Loss: 1.5118522644042969\n",
      "Epoch: 6 | [54000 / 60000] | Loss: 1.523718237876892\n",
      "Epoch: 6 | [56000 / 60000] | Loss: 1.5443484783172607\n",
      "Epoch: 6 | [58000 / 60000] | Loss: 1.5380841493606567\n",
      "Average Loss: 0.014928705990314484 | Correct: 9682 / 10000\n",
      "Epoch: 7 | [0 / 60000] | Loss: 1.4969748258590698\n",
      "Epoch: 7 | [2000 / 60000] | Loss: 1.5150973796844482\n",
      "Epoch: 7 | [4000 / 60000] | Loss: 1.50508713722229\n",
      "Epoch: 7 | [6000 / 60000] | Loss: 1.5869414806365967\n",
      "Epoch: 7 | [8000 / 60000] | Loss: 1.5479923486709595\n",
      "Epoch: 7 | [10000 / 60000] | Loss: 1.5530884265899658\n",
      "Epoch: 7 | [12000 / 60000] | Loss: 1.5777226686477661\n",
      "Epoch: 7 | [14000 / 60000] | Loss: 1.5238560438156128\n",
      "Epoch: 7 | [16000 / 60000] | Loss: 1.596196174621582\n",
      "Epoch: 7 | [18000 / 60000] | Loss: 1.515508770942688\n",
      "Epoch: 7 | [20000 / 60000] | Loss: 1.5154616832733154\n",
      "Epoch: 7 | [22000 / 60000] | Loss: 1.5898427963256836\n",
      "Epoch: 7 | [24000 / 60000] | Loss: 1.5536097288131714\n",
      "Epoch: 7 | [26000 / 60000] | Loss: 1.5351073741912842\n",
      "Epoch: 7 | [28000 / 60000] | Loss: 1.5576421022415161\n",
      "Epoch: 7 | [30000 / 60000] | Loss: 1.5563206672668457\n",
      "Epoch: 7 | [32000 / 60000] | Loss: 1.4938267469406128\n",
      "Epoch: 7 | [34000 / 60000] | Loss: 1.5517817735671997\n",
      "Epoch: 7 | [36000 / 60000] | Loss: 1.4945772886276245\n",
      "Epoch: 7 | [38000 / 60000] | Loss: 1.5753684043884277\n",
      "Epoch: 7 | [40000 / 60000] | Loss: 1.5492712259292603\n",
      "Epoch: 7 | [42000 / 60000] | Loss: 1.5246561765670776\n",
      "Epoch: 7 | [44000 / 60000] | Loss: 1.5429530143737793\n",
      "Epoch: 7 | [46000 / 60000] | Loss: 1.5285313129425049\n",
      "Epoch: 7 | [48000 / 60000] | Loss: 1.5311106443405151\n",
      "Epoch: 7 | [50000 / 60000] | Loss: 1.5373246669769287\n",
      "Epoch: 7 | [52000 / 60000] | Loss: 1.5045193433761597\n",
      "Epoch: 7 | [54000 / 60000] | Loss: 1.5379408597946167\n",
      "Epoch: 7 | [56000 / 60000] | Loss: 1.5345371961593628\n",
      "Epoch: 7 | [58000 / 60000] | Loss: 1.5458097457885742\n",
      "Average Loss: 0.014897724425792694 | Correct: 9716 / 10000\n",
      "Epoch: 8 | [0 / 60000] | Loss: 1.5301921367645264\n",
      "Epoch: 8 | [2000 / 60000] | Loss: 1.5368114709854126\n",
      "Epoch: 8 | [4000 / 60000] | Loss: 1.4831569194793701\n",
      "Epoch: 8 | [6000 / 60000] | Loss: 1.5153415203094482\n",
      "Epoch: 8 | [8000 / 60000] | Loss: 1.5041574239730835\n",
      "Epoch: 8 | [10000 / 60000] | Loss: 1.526973843574524\n",
      "Epoch: 8 | [12000 / 60000] | Loss: 1.5170294046401978\n",
      "Epoch: 8 | [14000 / 60000] | Loss: 1.5023245811462402\n",
      "Epoch: 8 | [16000 / 60000] | Loss: 1.518917441368103\n",
      "Epoch: 8 | [18000 / 60000] | Loss: 1.5651190280914307\n",
      "Epoch: 8 | [20000 / 60000] | Loss: 1.519591212272644\n",
      "Epoch: 8 | [22000 / 60000] | Loss: 1.5652260780334473\n",
      "Epoch: 8 | [24000 / 60000] | Loss: 1.5680617094039917\n",
      "Epoch: 8 | [26000 / 60000] | Loss: 1.5147595405578613\n",
      "Epoch: 8 | [28000 / 60000] | Loss: 1.569480538368225\n",
      "Epoch: 8 | [30000 / 60000] | Loss: 1.5198006629943848\n",
      "Epoch: 8 | [32000 / 60000] | Loss: 1.5630837678909302\n",
      "Epoch: 8 | [34000 / 60000] | Loss: 1.5349138975143433\n",
      "Epoch: 8 | [36000 / 60000] | Loss: 1.5110774040222168\n",
      "Epoch: 8 | [38000 / 60000] | Loss: 1.5210890769958496\n",
      "Epoch: 8 | [40000 / 60000] | Loss: 1.5305285453796387\n",
      "Epoch: 8 | [42000 / 60000] | Loss: 1.5497748851776123\n",
      "Epoch: 8 | [44000 / 60000] | Loss: 1.531423807144165\n",
      "Epoch: 8 | [46000 / 60000] | Loss: 1.518709659576416\n",
      "Epoch: 8 | [48000 / 60000] | Loss: 1.5225780010223389\n",
      "Epoch: 8 | [50000 / 60000] | Loss: 1.510042667388916\n",
      "Epoch: 8 | [52000 / 60000] | Loss: 1.5067856311798096\n",
      "Epoch: 8 | [54000 / 60000] | Loss: 1.5274145603179932\n",
      "Epoch: 8 | [56000 / 60000] | Loss: 1.5409528017044067\n",
      "Epoch: 8 | [58000 / 60000] | Loss: 1.5053322315216064\n",
      "Average Loss: 0.014894649505615235 | Correct: 9714 / 10000\n",
      "Epoch: 9 | [0 / 60000] | Loss: 1.51723051071167\n",
      "Epoch: 9 | [2000 / 60000] | Loss: 1.549028754234314\n",
      "Epoch: 9 | [4000 / 60000] | Loss: 1.513533353805542\n",
      "Epoch: 9 | [6000 / 60000] | Loss: 1.5382466316223145\n",
      "Epoch: 9 | [8000 / 60000] | Loss: 1.513411045074463\n",
      "Epoch: 9 | [10000 / 60000] | Loss: 1.5519541501998901\n",
      "Epoch: 9 | [12000 / 60000] | Loss: 1.5073623657226562\n",
      "Epoch: 9 | [14000 / 60000] | Loss: 1.536406397819519\n",
      "Epoch: 9 | [16000 / 60000] | Loss: 1.5360523462295532\n",
      "Epoch: 9 | [18000 / 60000] | Loss: 1.5922062397003174\n",
      "Epoch: 9 | [20000 / 60000] | Loss: 1.5106080770492554\n",
      "Epoch: 9 | [22000 / 60000] | Loss: 1.522990107536316\n",
      "Epoch: 9 | [24000 / 60000] | Loss: 1.5034730434417725\n",
      "Epoch: 9 | [26000 / 60000] | Loss: 1.5240368843078613\n",
      "Epoch: 9 | [28000 / 60000] | Loss: 1.568882703781128\n",
      "Epoch: 9 | [30000 / 60000] | Loss: 1.5000985860824585\n",
      "Epoch: 9 | [32000 / 60000] | Loss: 1.5515663623809814\n",
      "Epoch: 9 | [34000 / 60000] | Loss: 1.5295463800430298\n",
      "Epoch: 9 | [36000 / 60000] | Loss: 1.5187454223632812\n",
      "Epoch: 9 | [38000 / 60000] | Loss: 1.5245312452316284\n",
      "Epoch: 9 | [40000 / 60000] | Loss: 1.5604641437530518\n",
      "Epoch: 9 | [42000 / 60000] | Loss: 1.5143498182296753\n",
      "Epoch: 9 | [44000 / 60000] | Loss: 1.5312118530273438\n",
      "Epoch: 9 | [46000 / 60000] | Loss: 1.5308016538619995\n",
      "Epoch: 9 | [48000 / 60000] | Loss: 1.4859046936035156\n",
      "Epoch: 9 | [50000 / 60000] | Loss: 1.564774751663208\n",
      "Epoch: 9 | [52000 / 60000] | Loss: 1.5437732934951782\n",
      "Epoch: 9 | [54000 / 60000] | Loss: 1.5430444478988647\n",
      "Epoch: 9 | [56000 / 60000] | Loss: 1.4900140762329102\n",
      "Epoch: 9 | [58000 / 60000] | Loss: 1.5199180841445923\n",
      "Average Loss: 0.01488173326253891 | Correct: 9723 / 10000\n",
      "Epoch: 10 | [0 / 60000] | Loss: 1.510425090789795\n",
      "Epoch: 10 | [2000 / 60000] | Loss: 1.498746395111084\n",
      "Epoch: 10 | [4000 / 60000] | Loss: 1.5234689712524414\n",
      "Epoch: 10 | [6000 / 60000] | Loss: 1.5336108207702637\n",
      "Epoch: 10 | [8000 / 60000] | Loss: 1.5025508403778076\n",
      "Epoch: 10 | [10000 / 60000] | Loss: 1.532677412033081\n",
      "Epoch: 10 | [12000 / 60000] | Loss: 1.5644558668136597\n",
      "Epoch: 10 | [14000 / 60000] | Loss: 1.5296069383621216\n",
      "Epoch: 10 | [16000 / 60000] | Loss: 1.5190037488937378\n",
      "Epoch: 10 | [18000 / 60000] | Loss: 1.496568202972412\n",
      "Epoch: 10 | [20000 / 60000] | Loss: 1.5705652236938477\n",
      "Epoch: 10 | [22000 / 60000] | Loss: 1.5475916862487793\n",
      "Epoch: 10 | [24000 / 60000] | Loss: 1.5250067710876465\n",
      "Epoch: 10 | [26000 / 60000] | Loss: 1.4915775060653687\n",
      "Epoch: 10 | [28000 / 60000] | Loss: 1.569556713104248\n",
      "Epoch: 10 | [30000 / 60000] | Loss: 1.4900622367858887\n",
      "Epoch: 10 | [32000 / 60000] | Loss: 1.5272384881973267\n",
      "Epoch: 10 | [34000 / 60000] | Loss: 1.504489541053772\n",
      "Epoch: 10 | [36000 / 60000] | Loss: 1.5191071033477783\n",
      "Epoch: 10 | [38000 / 60000] | Loss: 1.5566864013671875\n",
      "Epoch: 10 | [40000 / 60000] | Loss: 1.533319354057312\n",
      "Epoch: 10 | [42000 / 60000] | Loss: 1.5265231132507324\n",
      "Epoch: 10 | [44000 / 60000] | Loss: 1.5289579629898071\n",
      "Epoch: 10 | [46000 / 60000] | Loss: 1.5141535997390747\n",
      "Epoch: 10 | [48000 / 60000] | Loss: 1.5411653518676758\n",
      "Epoch: 10 | [50000 / 60000] | Loss: 1.5280224084854126\n",
      "Epoch: 10 | [52000 / 60000] | Loss: 1.5375463962554932\n",
      "Epoch: 10 | [54000 / 60000] | Loss: 1.5210531949996948\n",
      "Epoch: 10 | [56000 / 60000] | Loss: 1.518295168876648\n",
      "Epoch: 10 | [58000 / 60000] | Loss: 1.5227807760238647\n",
      "Average Loss: 0.014868119573593139 | Correct: 9745 / 10000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: Models/01_model_0.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"Models\")\n",
    "MODEL_PATH.mkdir(parents=1, exist_ok=1)\n",
    "\n",
    "MODEL_NAME = \"01_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model1.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
